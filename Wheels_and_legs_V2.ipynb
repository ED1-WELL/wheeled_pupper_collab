{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ED1-WELL/wheeled_pupper_collab/blob/main/Wheels_and_legs_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gU9NdsOlmczp"
      },
      "source": [
        "# Authors\n",
        "Google (thanks Baruch!) + Nathan + Gabrael, minor modifications from Ankush and JC for CS 123 purposes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MOdG86sD9gb"
      },
      "source": [
        "# GPU\n",
        "Please connect to an **A100** GPU to run the following notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWNkLJXDLw6m"
      },
      "source": [
        "# Log in to Weights and Biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceWm771NPMum"
      },
      "source": [
        "Paste your wandb key in the section below to log all your training processes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DP34paxbOhnp"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "try:\n",
        "  wandb_key = userdata.get('wandb_key')\n",
        "except userdata.SecretNotFoundError:\n",
        "  # Paste your wandb key here\n",
        "  wandb_key = 'fe8596894517233dd099cb1bd8dfe76f9528b126'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Dn2fSg1ILt_J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d98bda9d-4fc4-42d1-ff1f-4426c9679ba9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Using explicit session credentials for https://api.wandb.ai.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33medretzka\u001b[0m (\u001b[33medretzka-university-of-wisconsin-madison\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "!pip install -q wandb\n",
        "import wandb\n",
        "wandb.login(key=wandb_key if wandb_key else None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvyGCsgSCxHQ"
      },
      "source": [
        "# Install dependencies (no need to open this)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Xqo7pyX-n72M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0b7e3fc-6b0b-4787-d302-e088c0c54bf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m998.9/998.9 kB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.2/424.2 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.5/243.5 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.4/172.4 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m740.4/740.4 kB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for orbax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pytinyrenderer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.9/88.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.0/55.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.9/268.9 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hFound existing installation: jax 0.7.2\n",
            "Uninstalling jax-0.7.2:\n",
            "  Successfully uninstalled jax-0.7.2\n",
            "Found existing installation: jaxlib 0.7.2\n",
            "Uninstalling jaxlib-0.7.2:\n",
            "  Successfully uninstalled jaxlib-0.7.2\n",
            "Found existing installation: optax 0.2.6\n",
            "Uninstalling optax-0.2.6:\n",
            "  Successfully uninstalled optax-0.2.6\n",
            "Found existing installation: orbax-checkpoint 0.11.31\n",
            "Uninstalling orbax-checkpoint-0.11.31:\n",
            "  Successfully uninstalled orbax-checkpoint-0.11.31\n",
            "Collecting optax==0.2.2\n",
            "  Downloading optax-0.2.2-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting orbax-checkpoint==0.11.10\n",
            "  Downloading orbax_checkpoint-0.11.10-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from optax==0.2.2) (1.4.0)\n",
            "Requirement already satisfied: chex>=0.1.86 in /usr/local/lib/python3.12/dist-packages (from optax==0.2.2) (0.1.90)\n",
            "Collecting jax>=0.1.55 (from optax==0.2.2)\n",
            "  Downloading jax-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib>=0.1.37 (from optax==0.2.2)\n",
            "  Downloading jaxlib-0.9.0-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.12/dist-packages (from optax==0.2.2) (2.0.2)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint==0.11.10) (1.13.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint==0.11.10) (4.15.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint==0.11.10) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint==0.11.10) (6.0.3)\n",
            "Requirement already satisfied: tensorstore>=0.1.71 in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint==0.11.10) (0.1.80)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint==0.11.10) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint==0.11.10) (5.29.5)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint==0.11.10) (4.15.0)\n",
            "Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint==0.11.10) (3.20.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from chex>=0.1.86->optax==0.2.2) (75.2.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chex>=0.1.86->optax==0.2.2) (0.12.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax>=0.1.55->optax==0.2.2) (0.5.4)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax>=0.1.55->optax==0.2.2) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.13 in /usr/local/lib/python3.12/dist-packages (from jax>=0.1.55->optax==0.2.2) (1.16.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint==0.11.10) (2025.3.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint==0.11.10) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint==0.11.10) (3.23.0)\n",
            "Downloading optax-0.2.2-py3-none-any.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orbax_checkpoint-0.11.10-py3-none-any.whl (376 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.9/376.9 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax-0.9.0-py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.9.0-cp312-cp312-manylinux_2_27_x86_64.whl (80.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jaxlib, jax, orbax-checkpoint, optax\n",
            "Successfully installed jax-0.9.0 jaxlib-0.9.0 optax-0.2.2 orbax-checkpoint-0.11.10\n",
            "Collecting jax==0.5.0 (from jax[cuda12]==0.5.0)\n",
            "  Downloading jax-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jax-cuda12-plugin==0.5.0\n",
            "  Downloading jax_cuda12_plugin-0.5.0-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax-triton==0.2.0\n",
            "  Downloading jax_triton-0.2.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting jaxlib<=0.5.0,>=0.5.0 (from jax==0.5.0->jax[cuda12]==0.5.0)\n",
            "  Downloading jaxlib-0.5.0-cp312-cp312-manylinux2014_x86_64.whl.metadata (978 bytes)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from jax==0.5.0->jax[cuda12]==0.5.0) (0.5.4)\n",
            "Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.12/dist-packages (from jax==0.5.0->jax[cuda12]==0.5.0) (2.0.2)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax==0.5.0->jax[cuda12]==0.5.0) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.12/dist-packages (from jax==0.5.0->jax[cuda12]==0.5.0) (1.16.3)\n",
            "Collecting jax-cuda12-pjrt==0.5.0 (from jax-cuda12-plugin==0.5.0)\n",
            "  Downloading jax_cuda12_pjrt-0.5.0-py3-none-manylinux2014_x86_64.whl.metadata (348 bytes)\n",
            "Requirement already satisfied: absl-py>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from jax-triton==0.2.0) (1.4.0)\n",
            "Requirement already satisfied: triton>=3.1 in /usr/local/lib/python3.12/dist-packages (from jax-triton==0.2.0) (3.5.0)\n",
            "Requirement already satisfied: nvidia-cublas-cu12>=12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.0,>=0.5.0; extra == \"cuda12\"->jax[cuda12]==0.5.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12>=12.1.105 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.0,>=0.5.0; extra == \"cuda12\"->jax[cuda12]==0.5.0) (12.6.80)\n",
            "Collecting nvidia-cuda-nvcc-cu12>=12.6.85 (from jax-cuda12-plugin[with_cuda]<=0.5.0,>=0.5.0; extra == \"cuda12\"->jax[cuda12]==0.5.0)\n",
            "  Downloading nvidia_cuda_nvcc_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12>=12.1.105 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.0,>=0.5.0; extra == \"cuda12\"->jax[cuda12]==0.5.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12<10.0,>=9.1 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.0,>=0.5.0; extra == \"cuda12\"->jax[cuda12]==0.5.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cufft-cu12>=11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.0,>=0.5.0; extra == \"cuda12\"->jax[cuda12]==0.5.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12>=11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.0,>=0.5.0; extra == \"cuda12\"->jax[cuda12]==0.5.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12>=12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.0,>=0.5.0; extra == \"cuda12\"->jax[cuda12]==0.5.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12>=2.18.1 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.0,>=0.5.0; extra == \"cuda12\"->jax[cuda12]==0.5.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12>=12.1.105 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.0,>=0.5.0; extra == \"cuda12\"->jax[cuda12]==0.5.0) (12.6.85)\n",
            "Downloading jax-0.5.0-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax_cuda12_plugin-0.5.0-cp312-cp312-manylinux2014_x86_64.whl (16.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax_triton-0.2.0-py3-none-any.whl (27 kB)\n",
            "Downloading jax_cuda12_pjrt-0.5.0-py3-none-manylinux2014_x86_64.whl (103.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.5.0-cp312-cp312-manylinux2014_x86_64.whl (102.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.0/102.0 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvcc_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (40.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jax-cuda12-pjrt, nvidia-cuda-nvcc-cu12, jax-cuda12-plugin, jaxlib, jax, jax-triton\n",
            "  Attempting uninstall: jax-cuda12-pjrt\n",
            "    Found existing installation: jax-cuda12-pjrt 0.7.2\n",
            "    Uninstalling jax-cuda12-pjrt-0.7.2:\n",
            "      Successfully uninstalled jax-cuda12-pjrt-0.7.2\n",
            "  Attempting uninstall: nvidia-cuda-nvcc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvcc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvcc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvcc-cu12-12.5.82\n",
            "  Attempting uninstall: jax-cuda12-plugin\n",
            "    Found existing installation: jax-cuda12-plugin 0.7.2\n",
            "    Uninstalling jax-cuda12-plugin-0.7.2:\n",
            "      Successfully uninstalled jax-cuda12-plugin-0.7.2\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.9.0\n",
            "    Uninstalling jaxlib-0.9.0:\n",
            "      Successfully uninstalled jaxlib-0.9.0\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.9.0\n",
            "    Uninstalling jax-0.9.0:\n",
            "      Successfully uninstalled jax-0.9.0\n",
            "Successfully installed jax-0.5.0 jax-cuda12-pjrt-0.5.0 jax-cuda12-plugin-0.5.0 jax-triton-0.2.0 jaxlib-0.5.0 nvidia-cuda-nvcc-cu12-12.9.86\n"
          ]
        }
      ],
      "source": [
        "!pip install -q mujoco==3.2.7 mujoco-mjx==3.2.7 brax==0.10.5 flax==0.10.2 orbax==0.1.9\n",
        "!pip install black[jupyter] --quiet\n",
        "import os\n",
        "# Tell XLA to use Triton GEMM, this improves steps/sec by ~30% on some GPUs\n",
        "xla_flags = os.environ.get('XLA_FLAGS', '')\n",
        "xla_flags += ' --xla_gpu_triton_gemm_any=True'\n",
        "os.environ['XLA_FLAGS'] = xla_flags\n",
        "# Clean up incompatible jax versions\n",
        "!pip uninstall -y jax jaxlib optax orbax-checkpoint\n",
        "\n",
        "# Install specific compatible jax versions\n",
        "!pip install optax==0.2.2 orbax-checkpoint==0.11.10\n",
        "!pip install \"jax[cuda12]==0.5.0\" \"jax-cuda12-plugin==0.5.0\" \"jax-triton==0.2.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IbZxYDxzoz5R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df552784-e9d3-4d16-8294-9b4a4eb9ea3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting environment variable to use GPU rendering:\n",
            "env: MUJOCO_GL=egl\n",
            "Checking that the installation succeeded:\n",
            "Installation successful.\n"
          ]
        }
      ],
      "source": [
        "#@title Check if MuJoCo installation was successful\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "import distutils.util\n",
        "import os\n",
        "import subprocess\n",
        "if subprocess.run('nvidia-smi').returncode:\n",
        "  raise RuntimeError(\n",
        "      'Cannot communicate with GPU. '\n",
        "      'Make sure you are using a GPU Colab runtime. '\n",
        "      'Go to the Runtime menu and select Choose runtime type.')\n",
        "\n",
        "# Add an ICD config so that glvnd can pick up the Nvidia EGL driver.\n",
        "# This is usually installed as part of an Nvidia driver package, but the Colab\n",
        "# kernel doesn't install its driver via APT, and as a result the ICD is missing.\n",
        "# (https://github.com/NVIDIA/libglvnd/blob/master/src/EGL/icd_enumeration.md)\n",
        "NVIDIA_ICD_CONFIG_PATH = '/usr/share/glvnd/egl_vendor.d/10_nvidia.json'\n",
        "if not os.path.exists(NVIDIA_ICD_CONFIG_PATH):\n",
        "  with open(NVIDIA_ICD_CONFIG_PATH, 'w') as f:\n",
        "    f.write(\"\"\"{\n",
        "    \"file_format_version\" : \"1.0.0\",\n",
        "    \"ICD\" : {\n",
        "        \"library_path\" : \"libEGL_nvidia.so.0\"\n",
        "    }\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "# Tell XLA to use Triton GEMM, this improves steps/sec by ~30% on some GPUs\n",
        "xla_flags = os.environ.get('XLA_FLAGS', '')\n",
        "xla_flags += ' --xla_gpu_triton_gemm_any=True'\n",
        "os.environ['XLA_FLAGS'] = xla_flags\n",
        "\n",
        "# Configure MuJoCo to use the EGL rendering backend (requires GPU)\n",
        "print('Setting environment variable to use GPU rendering:')\n",
        "%env MUJOCO_GL=egl\n",
        "\n",
        "try:\n",
        "  print('Checking that the installation succeeded:')\n",
        "  import mujoco\n",
        "  mujoco.MjModel.from_xml_string('<mujoco/>')\n",
        "except Exception as e:\n",
        "  raise e from RuntimeError(\n",
        "      'Something went wrong during installation. Check the shell output above '\n",
        "      'for more information.\\n'\n",
        "      'If using a hosted Colab runtime, make sure you enable GPU acceleration '\n",
        "      'by going to the Runtime menu and selecting \"Choose runtime type\".')\n",
        "\n",
        "print('Installation successful.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "T5f4w3Kq2X14",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70a67836-96cf-425f-c1ad-d26b3924bd28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing mediapy:\n"
          ]
        }
      ],
      "source": [
        "#@title Import packages for plotting and creating graphics\n",
        "import time\n",
        "import itertools\n",
        "import numpy as np\n",
        "from typing import Callable, NamedTuple, Optional, Union, List\n",
        "\n",
        "# Graphics and plotting.\n",
        "print('Installing mediapy:')\n",
        "!command -v ffmpeg >/dev/null || (apt update && apt install -y ffmpeg)\n",
        "!pip install -q mediapy\n",
        "import mediapy as media\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# More legible printing from numpy.\n",
        "np.set_printoptions(precision=3, suppress=True, linewidth=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ObF1UXrkb0Nd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6142ac03-3d31-4ab6-8d36-f0dd2455ab31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "#@title Import MuJoCo, MJX, and Brax\n",
        "\n",
        "\n",
        "from datetime import datetime\n",
        "import functools\n",
        "from IPython.display import HTML\n",
        "import jax\n",
        "from jax import numpy as jp\n",
        "import numpy as np\n",
        "from typing import Any, Dict, Sequence, Tuple, Union\n",
        "\n",
        "from brax import base\n",
        "from brax import envs\n",
        "from brax import math\n",
        "from brax.base import Base, Motion, Transform\n",
        "from brax.envs.base import Env, PipelineEnv, State\n",
        "from brax.mjx.base import State as MjxState\n",
        "from brax.training.agents.ppo import train as ppo\n",
        "from brax.training.agents.ppo import networks as ppo_networks\n",
        "from brax.io import html, mjcf, model\n",
        "\n",
        "from etils import epath\n",
        "from flax import struct\n",
        "from matplotlib import pyplot as plt\n",
        "import mediapy as media\n",
        "from ml_collections import config_dict\n",
        "import mujoco\n",
        "from mujoco import mjx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y262K4V6mQWO"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7y2mHlcs-uc"
      },
      "source": [
        "## pupperv3-mjx repo config (no need to open this)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-RWANdG-pksC"
      },
      "outputs": [],
      "source": [
        "pupperv3_mjx_config = config_dict.ConfigDict()\n",
        "pupperv3_mjx_config.branch = \"Wheeled\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "EvhB8kedFkLi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff70e0a5-f602-4db4-e4b6-5d30d3fa26ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'pupperv3-mjx' already exists and is not an empty directory.\n",
            "Already up to date.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pupperv3_mjx (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!rm -rf pupperv3_mjx\n",
        "# Using JC's version in case there's an update in the future\n",
        "!git clone https://github.com/ED1-WELL/pupperv3-mjx.git -b {pupperv3_mjx_config.branch}\n",
        "!mv pupperv3-mjx pupperv3_mjx\n",
        "!cd pupperv3_mjx && git pull && pip install -q ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nZRV6QEu2sk"
      },
      "source": [
        "## Simulation Config (no need to open this)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6yqn-xUQGpg3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dafab355-c219-4359-c016-275940203c26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pupper_v3_description'...\n",
            "remote: Enumerating objects: 669, done.\u001b[K\n",
            "remote: Counting objects: 100% (317/317), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 669 (delta 304), reused 271 (delta 270), pack-reused 352 (from 1)\u001b[K\n",
            "Receiving objects: 100% (669/669), 14.66 MiB | 12.75 MiB/s, done.\n",
            "Resolving deltas: 100% (484/484), done.\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "# Pupper model configuration\n",
        "simulation_config = config_dict.ConfigDict()\n",
        "simulation_config.model_repo = 'https://github.com/ED1-WELL/pupper_v3_description'\n",
        "simulation_config.model_branch = 'Wheeled'\n",
        "\n",
        "!rm -rf pupper_v3_description\n",
        "!git clone {simulation_config.model_repo} -b {simulation_config.model_branch}\n",
        "!cd pupper_v3_description && git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hlfOsZOf2BeB"
      },
      "outputs": [],
      "source": [
        "# Select model\n",
        "# simulation_config.original_model_path = 'pupper_v3_description/description/mujoco_xml/pupper_v3_complete.mjx.position.no_body.self_collision.stable.xml'\n",
        "# simulation_config.original_model_path = 'pupper_v3_description/description/mujoco_xml/pupper_v3_complete.mjx.position.no_body.self_collision.less_stable.xml'\n",
        "\n",
        "# simulation_config.original_model_path = 'pupper_v3_description/description/mujoco_xml/pupper_v3_complete.mjx.position.no_body.self_collision.weak.xml' # 2Nm max\n",
        "#simulation_config.original_model_path = 'pupper_v3_description/description/mujoco_xml/pupper_v3_complete.mjx.position.no_body.self_collision.two_iterations.xml' # 3Nm max\n",
        "simulation_config.original_model_path = 'pupper_v3_description/description/mujoco_xml/wheels_and_legs.xml' # 3Nm max\n",
        "# simulation_config.original_model_path = 'pupper_v3_description/description/mujoco_xml/pupper_v3_complete.mjx.position.no_body.self_collision.xml' # 3Nm max\n",
        "\n",
        "# simulation_config.original_model_path = 'pupper_v3_description/description/mujoco_xml/pupper_v3_complete.mjx.position.no_body.xml'\n",
        "# simulation_config.original_model_path = 'pupper_v3_description/description/mujoco_xml/pupper_v3_complete.mjx.position.xml'\n",
        "simulation_config.model_xml = epath.Path(simulation_config.original_model_path).read_text()\n",
        "simulation_config.model_path = \"pupper_v3_description/description/mujoco_xml/model_with_obstacles.xml\"\n",
        "\n",
        "# Model body names\n",
        "simulation_config.upper_leg_body_names = [\"leg_front_r_2\", \"leg_front_l_2\", \"leg_back_r_2\", \"leg_back_l_2\"]\n",
        "simulation_config.lower_leg_body_names = [\"leg_front_r_3\", \"leg_front_l_3\", \"leg_back_r_3\", \"leg_back_l_3\"]\n",
        "#simulation_config.lower_leg_body_names = [\"Wheel_FR\",\"Wheel_FL\",\"Wheel_BR\",\"Wheel_BL\"]\n",
        "simulation_config.foot_site_names = [\n",
        "    \"leg_front_r_3_foot_site\",\n",
        "    \"leg_front_l_3_foot_site\",\n",
        "    \"leg_back_r_3_foot_site\",\n",
        "    \"leg_back_l_3_foot_site\",\n",
        "]\n",
        "simulation_config.torso_name = \"base_link\"\n",
        "\n",
        "# Foot radius\n",
        "simulation_config.foot_radius = 0.02\n",
        "\n",
        "# Collision detection\n",
        "simulation_config.max_contact_points = 8 # Default: 5 # 8\n",
        "simulation_config.max_geom_pairs = 8 # Default: 4 # 8\n",
        "\n",
        "# TODO: This introduces a fundamental limit to the policy performance\n",
        "# What happens here is we set the maximum angle that can be commanded to the\n",
        "# joint equal to the actual joint limit. However, imagine if the joint is already\n",
        "# near its limit. There's no way we can apply torque in the direction towards\n",
        "# the limit because the max command is the joint limit. To allow torque even at\n",
        "# the limit. We will need to increase the upper and lower limits and somehow\n",
        "# penalize the robot for hitting the joint limits.\n",
        "\n",
        "# Joint limits\n",
        "sys_temp = mjcf.load(simulation_config.original_model_path)\n",
        "joint_upper_limits = sys_temp.jnt_range[1:, 1]\n",
        "joint_lower_limits = sys_temp.jnt_range[1:, 0]\n",
        "simulation_config.joint_upper_limits = np.array(joint_upper_limits).tolist()\n",
        "simulation_config.joint_lower_limits = np.array(joint_lower_limits).tolist()\n",
        "\n",
        "# Physics timestep\n",
        "simulation_config.physics_dt = 0.004 # Physics dt [s]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1neH_vwu2Ku"
      },
      "source": [
        "## Training Config\n",
        "\n",
        "Training configs include:\n",
        "\n",
        "*   configs controlling PPO (policy learning optimizer)\n",
        "*   default joint angles\n",
        "*   height fields\n",
        "*   domain randomization parameters\n",
        "\n",
        "**Modify with caution!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dctacKGKufq9"
      },
      "outputs": [],
      "source": [
        "from pupperv3_mjx import domain_randomization\n",
        "\n",
        "import importlib\n",
        "\n",
        "importlib.reload(domain_randomization)\n",
        "\n",
        "training_config = config_dict.ConfigDict()\n",
        "training_config.checkpoint_run_number = None\n",
        "\n",
        "# Environment timestep\n",
        "training_config.environment_dt = 0.02\n",
        "\n",
        "# PPO params\n",
        "training_config.ppo = config_dict.ConfigDict()\n",
        "training_config.ppo.num_timesteps = 300_000_000   # Default: 300M\n",
        "training_config.ppo.episode_length = 500         # Default: 1000\n",
        "training_config.ppo.num_evals = 11                # Default: 10\n",
        "training_config.ppo.reward_scaling = 1            # Default: 1\n",
        "training_config.ppo.normalize_observations = True # Default: True\n",
        "training_config.ppo.action_repeat = 1             # Default: 1\n",
        "training_config.ppo.unroll_length = 20            # Default: 20\n",
        "training_config.ppo.num_minibatches = 32          # Default: 32\n",
        "training_config.ppo.num_updates_per_batch = 4     # Default: 4\n",
        "training_config.ppo.discounting = 0.97            # Default: 0.97\n",
        "training_config.ppo.learning_rate = 3.0e-5        # Default: 3.0e-4, 3.0e-5 was better than 3e-4\n",
        "training_config.ppo.entropy_cost = 1e-2           # Default: 1e-2\n",
        "training_config.ppo.num_envs = 8192               # Default: 8192\n",
        "training_config.ppo.batch_size = 256              # Default: 256\n",
        "\n",
        "# Command sampling\n",
        "training_config.resample_velocity_step = training_config.ppo.episode_length // 2\n",
        "training_config.lin_vel_x_range = [-0.75, 0.75]  # min max [m/s]. Default: [-0.75, 0.75]\n",
        "training_config.lin_vel_y_range = [-0.5, 0.5]  # min max [m/s]. Default: [-0.5, 0.5]\n",
        "training_config.ang_vel_yaw_range = [-2.0, 2.0]  # min max [rad/s]. Default: [-2.0, 2.0]\n",
        "training_config.zero_command_probability = 0.02\n",
        "training_config.stand_still_command_threshold = 0.05\n",
        "\n",
        "# Orientation command sampling in degrees\n",
        "training_config.maximum_pitch_command = 0.0\n",
        "training_config.maximum_roll_command = 0.0\n",
        "\n",
        "# Desired body orientation\n",
        "training_config.desired_world_z_in_body_frame = (0.0, 0.0, 1.0) # Default: (0.0, 0.0, 1.0)\n",
        "\n",
        "# Termination\n",
        "# NOTE: without a body collision geometry, can't train recovery policy\n",
        "training_config.terminal_body_z = 0.1  # Episode ends if body center goes below this height [m] Default: 0.10 m\n",
        "training_config.terminal_body_angle = 0.52  # Episode ends if body angle relative to vertical is more than this. Default: 0.52 rad (30 deg)\n",
        "training_config.early_termination_step_threshold = training_config.ppo.episode_length // 2 # Default: 500\n",
        "\n",
        "# Joint PD overrides\n",
        "training_config.dof_damping = 0.25  # Joint damping [Nm / (rad/s)] Default: 0.25\n",
        "training_config.position_control_kp = 5.5  # Joint stiffness [Nm / rad] Default: 5.0\n",
        "\n",
        "# Default joint angles\n",
        "training_config.default_pose = jp.array(\n",
        "    [0.26, 0.0, -0.52, -0.26, 0.0, 0.52, 0.26, 0.0, -0.52, -0.26, 0.0, 0.52]\n",
        ")\n",
        "\n",
        "# Desired abduction angles\n",
        "training_config.desired_abduction_angles = jp.array(\n",
        "    [0.0, 0.0, 0.0, 0.0]\n",
        ")\n",
        "\n",
        "# Height field\n",
        "## Type of height field\n",
        "training_config.height_field_random = False\n",
        "training_config.height_field_steps = False\n",
        "### Steps type params\n",
        "training_config.height_field_step_size = 4\n",
        "## General height field settings\n",
        "training_config.height_field_grid_size = 256\n",
        "training_config.height_field_group = \"0\"\n",
        "training_config.height_field_radius_x = 10.0 # [m]\n",
        "training_config.height_field_radius_y = 10.0 # [m]\n",
        "training_config.height_field_elevation_z = 0.02 # [m]\n",
        "training_config.height_field_base_z = 0.2 # [m]\n",
        "\n",
        "# Domain randomization\n",
        "## Perturbations\n",
        "training_config.kick_probability = 0.0        # Kick the robot with this probability. ( ͡° ͜ʖ ͡°) Default: 0.04\n",
        "training_config.kick_vel = 0.10               # Change the torso velocity by up to this much in x and y direction to simulate a kick [m/s] Default: 0.1\n",
        "training_config.angular_velocity_noise = 0.1  # Default: 0.1 [rad/s]\n",
        "training_config.gravity_noise = 0.05            # Default: 0.05 [u]\n",
        "training_config.motor_angle_noise = 0.05        # Default: 0.05 [rad]\n",
        "training_config.last_action_noise = 0.01       # Default: 0.01 [rad]\n",
        "\n",
        "## Motors\n",
        "training_config.position_control_kp_multiplier_range = (0.6, 1.1)\n",
        "training_config.position_control_kd_multiplier_range = (0.8, 1.5)\n",
        "\n",
        "## Starting position\n",
        "training_config.start_position_config = domain_randomization.StartPositionRandomization(\n",
        "    x_min=-2.0, x_max=2.0, y_min=-2.0, y_max=2.0, z_min=0.15, z_max=0.20\n",
        ")\n",
        "\n",
        "## Latency distribution\n",
        "# Action latency\n",
        "# 0 latency with 20% prob, 1 timestep latency with 80% prob\n",
        "training_config.latency_distribution = jp.array([0.2, 0.8])\n",
        "\n",
        "# IMU latency\n",
        "# 0 latency with 50% prob, 1 timestep latency with 50% prob\n",
        "training_config.imu_latency_distribution = jp.array([0.5, 0.5])\n",
        "\n",
        "## Body CoM\n",
        "training_config.body_com_x_shift_range = (-0.02, 0.02) # Default: -0.02, 0.02\n",
        "training_config.body_com_y_shift_range = (-0.005, 0.005)\n",
        "training_config.body_com_z_shift_range = (-0.005, 0.005)\n",
        "\n",
        "## Mass and inertia randomization for all bodies\n",
        "training_config.body_mass_scale_range = (0.9, 1.3)\n",
        "training_config.body_inertia_scale_range = (0.9, 1.3)\n",
        "\n",
        "## Friction\n",
        "training_config.friction_range = (0.6, 1.4)\n",
        "\n",
        "# Obstacles\n",
        "training_config.n_obstacles = 0\n",
        "training_config.obstacle_x_range = (-3.0, 3.0)  # [m]\n",
        "training_config.obstacle_y_range = (-3.0, 3.0)  # [m]\n",
        "training_config.obstacle_height = 0.04  # [m]\n",
        "training_config.obstacle_length = 2.0  # [m]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwgi-va9DWdJ"
      },
      "source": [
        "## Policy config\n",
        "\n",
        "These configs determine the policy architecure.\n",
        "\n",
        "Don't change anything in this section unless you are absolutely sure what you are doing :-)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HPOeTIpIDXli"
      },
      "outputs": [],
      "source": [
        "policy_config = config_dict.ConfigDict()\n",
        "\n",
        "policy_config.use_imu = True # Whether to use IMU in policy. Default: True\n",
        "\n",
        "policy_config.observation_history = 20  # number of stacked observations to give the policy\n",
        "\n",
        "policy_config.action_scale = 0.75  # Default 0.75\n",
        "\n",
        "policy_config.hidden_layer_sizes = (256, 128, 128, 128) # default (256, 128, 128, 128)\n",
        "\n",
        "# RTNeural supports relu, tanh, sigmoid (not great), softmax, elu, prelu\n",
        "# Swish was really good in terms of training but not supported in RTNeural rn\n",
        "policy_config.activation = \"elu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hrx6uBAxEW0"
      },
      "source": [
        "##Reward Configuration\n",
        "Below are the reward coefficients that you will adjust to guide the policy toward maximizing the desired behaviors.\n",
        "\n",
        "Most of the work for this lab will focus on **tuning these coefficients**!\n",
        "\n",
        "Be sure to carefully review the lab instructions to understand the exact implementation of each reward term — this is crucial for deciding whether each coefficient should be positive or negative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "GYq1SKJww5PY"
      },
      "outputs": [],
      "source": [
        "reward_config = config_dict.ConfigDict()\n",
        "reward_config.rewards = config_dict.ConfigDict()\n",
        "reward_config.rewards.scales = config_dict.ConfigDict()\n",
        "\n",
        "# Track linear velocity\n",
        "reward_config.rewards.scales.tracking_lin_vel = 5\n",
        "\n",
        "# Track the angular velocity along z-axis, i.e. yaw rate.\n",
        "reward_config.rewards.scales.tracking_ang_vel = 5\n",
        "\n",
        "# Track the given body orientation (desired world z axis in body frame)\n",
        "# Not working right nowkick\n",
        "reward_config.rewards.scales.tracking_orientation = 0.5\n",
        "\n",
        "# Below are regularization terms, we roughly divide the\n",
        "# terms to base state regularizations, joint\n",
        "# regularizations, and other behavior regularizations.\n",
        "# Penalize the base velocity in z direction, L2 penalty.\n",
        "reward_config.rewards.scales.lin_vel_z = -0.5\n",
        "\n",
        "# Penalize the base roll and pitch rate. L2 penalty.\n",
        "reward_config.rewards.scales.ang_vel_xy = -0.05\n",
        "\n",
        "# Penalize non-zero roll and pitch angles. L2 penalty.\n",
        "reward_config.rewards.scales.orientation = -0.5\n",
        "\n",
        "# L2 regularization of joint torques, sum(|tau|^2).\n",
        "reward_config.rewards.scales.torques = -0.0001\n",
        "\n",
        "# L2 regularization of joint accelerations sum(|qdd|^2)\n",
        "reward_config.rewards.scales.joint_acceleration = -1e-7\n",
        "\n",
        "# L1 regularization of mechanical work, |v * tau|.\n",
        "reward_config.rewards.scales.mechanical_work = 0\n",
        "\n",
        "# Penalize the change in the action and encourage smooth\n",
        "# actions. L1 regularization |action - last_action|^2\n",
        "reward_config.rewards.scales.action_rate = -0.01\n",
        "\n",
        "# Encourage long swing steps. However, it does not\n",
        "# encourage high clearances.\n",
        "reward_config.rewards.scales.feet_air_time = 0\n",
        "\n",
        "# Encourage joints at default position at zero command, L1 regularization\n",
        "# |q - q_default|.\n",
        "reward_config.rewards.scales.stand_still = 0\n",
        "\n",
        "# Encourage zero joint velocity at zero command, L1 regularization\n",
        "# |q_dot|.\n",
        "# Activates when norm(command) < stand_still_command_threshold\n",
        "# Commands below this threshold are sampled with probability zero_command_probability\n",
        "reward_config.rewards.scales.stand_still_joint_velocity = 0\n",
        "\n",
        "# Encourage zero abduction angle so legs don't spread so far out\n",
        "# L2 loss on ||abduction_motors - desired||^2\n",
        "reward_config.rewards.scales.abduction_angle = -0.3\n",
        "\n",
        "# Early termination penalty.\n",
        "reward_config.rewards.scales.termination = -100\n",
        "\n",
        "# Penalizing foot slipping on the ground.\n",
        "reward_config.rewards.scales.foot_slip = 0\n",
        "\n",
        "# Penalize knees hitting the ground\n",
        "reward_config.rewards.scales.knee_collision = -1.0\n",
        "\n",
        "# Penalize body hitting ground\n",
        "reward_config.rewards.scales.body_collision = -2.0\n",
        "\n",
        "# Tracking reward = exp(-error^2/sigma).\n",
        "reward_config.rewards.tracking_sigma = 0.25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-gxymQh6gQg"
      },
      "source": [
        "##Export config (no need to open this)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bqw0rOF6jGd"
      },
      "outputs": [],
      "source": [
        "# Define the path to the subdirectory\n",
        "export_config = config_dict.ConfigDict()\n",
        "export_config.gdrive_save_dir = '/content/drive/MyDrive/pupper_policies'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncR52Hvl3ZOn"
      },
      "source": [
        "## Github repo config (no need to open this)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LIhbybr3Yp2"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "def get_hash():\n",
        "  return subprocess.check_output(['git', 'rev-parse', 'HEAD']).strip().decode('utf-8')\n",
        "\n",
        "repo_config = config_dict.ConfigDict()\n",
        "%cd /content/pupperv3_mjx\n",
        "repo_config.pupperv3_mjx_hash = get_hash()\n",
        "%cd /content/pupper_v3_description\n",
        "repo_config.pupper_v3_description_hash = get_hash()\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mi69q6o5X8qC"
      },
      "source": [
        "## Create aggregated config (no need to open this)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xE_9GLezQ6bF"
      },
      "outputs": [],
      "source": [
        "temp_config = config_dict.ConfigDict()\n",
        "temp_config.simulation = simulation_config\n",
        "temp_config.training = training_config\n",
        "temp_config.policy = policy_config\n",
        "temp_config.reward = reward_config\n",
        "temp_config.export = export_config\n",
        "temp_config.repo = repo_config\n",
        "temp_config.pupperv3_mjx = pupperv3_mjx_config\n",
        "\n",
        "CONFIG = config_dict.FrozenConfigDict(temp_config)\n",
        "\n",
        "# Prevent user from accidentally making changes to these configs which are not used\n",
        "del temp_config, reward_config, policy_config, training_config, simulation_config, export_config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrkA-Nhi1ora"
      },
      "source": [
        "# Modify robot model\n",
        "\n",
        "This section modifies the mjx environment. You won't need to know what's going on here for this lab :-)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iKn6sSo7kSy"
      },
      "source": [
        "##Set contact options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kagHlf-9hiS"
      },
      "outputs": [],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "xml_str = epath.Path(CONFIG.simulation.original_model_path).read_text()\n",
        "tree = ET.ElementTree(ET.fromstring(xml_str))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9VHtcfo-00v"
      },
      "outputs": [],
      "source": [
        "from pupperv3_mjx import utils\n",
        "import importlib\n",
        "importlib.reload(utils)\n",
        "\n",
        "tree = utils.set_mjx_custom_options(tree,\n",
        "                                    max_contact_points=CONFIG.simulation.max_contact_points,\n",
        "                                    max_geom_pairs=CONFIG.simulation.max_geom_pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IYebF8y7na8"
      },
      "source": [
        "##Add obstacles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LXFwF8oUKwc0"
      },
      "outputs": [],
      "source": [
        "from pupperv3_mjx import obstacles\n",
        "import importlib\n",
        "importlib.reload(obstacles)\n",
        "\n",
        "tree = obstacles.add_boxes_to_model(\n",
        "    tree,\n",
        "    n_boxes=CONFIG.training.n_obstacles,\n",
        "    x_range=CONFIG.training.obstacle_x_range,\n",
        "    y_range=CONFIG.training.obstacle_y_range,\n",
        "    height=CONFIG.training.obstacle_height,\n",
        "    # depth=CONFIG.training.obstacle_depth,\n",
        "    length=CONFIG.training.obstacle_length\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijJ3bxAGbZcn"
      },
      "source": [
        "## Add height field ground"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIpy5gLTygZQ"
      },
      "outputs": [],
      "source": [
        "if CONFIG.training.height_field_random or CONFIG.training.height_field_steps:\n",
        "  if CONFIG.training.height_field_random:\n",
        "    # Height field with 8cm resolution\n",
        "    noise = np.array(jax.random.uniform(jax.random.PRNGKey(0), (CONFIG.training.height_field_grid_size, CONFIG.training.height_field_grid_size)))\n",
        "\n",
        "    # Height field with 1m resolution\n",
        "    area_noise = jax.random.uniform(jax.random.PRNGKey(1),\n",
        "    (1*int(CONFIG.training.height_field_grid_size//CONFIG.training.height_field_radius_x),\n",
        "      1*int(CONFIG.training.height_field_grid_size//CONFIG.training.height_field_radius_y)))\n",
        "    upscaled_area_noise = np.array(jax.image.resize(image=area_noise,\n",
        "                                                  shape=(CONFIG.training.height_field_grid_size, CONFIG.training.height_field_grid_size),\n",
        "                                                  method=\"nearest\"))\n",
        "\n",
        "    # Height field where\n",
        "    scaled_noise = noise * upscaled_area_noise\n",
        "\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    axs[0].imshow(noise, cmap='viridis')\n",
        "    axs[0].set_title('High resolution base noise')\n",
        "    axs[1].imshow(area_noise, cmap='viridis')\n",
        "    axs[1].set_title('Low resolution noise to make discrete areas')\n",
        "    axs[2].imshow(scaled_noise, cmap='viridis')\n",
        "    axs[2].set_title('Final height field noise')\n",
        "\n",
        "  if CONFIG.training.height_field_steps:\n",
        "    # steps with 24cm width\n",
        "    steps = jax.random.uniform(jax.random.PRNGKey(0),\n",
        "                                (CONFIG.training.height_field_grid_size//CONFIG.training.height_field_step_size,\n",
        "                                 CONFIG.training.height_field_grid_size//CONFIG.training.height_field_step_size))\n",
        "    scaled_noise = np.array(jax.image.resize(image=steps,\n",
        "                                    shape=(CONFIG.training.height_field_grid_size, CONFIG.training.height_field_grid_size),\n",
        "                                    method=\"nearest\"))\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    axs[0].imshow(steps, cmap='viridis')\n",
        "    axs[0].set_title('Low resolution step heights')\n",
        "    axs[1].imshow(scaled_noise, cmap='viridis')\n",
        "    axs[1].set_title('Final height field noise')\n",
        "\n",
        "\n",
        "  root = tree.getroot()\n",
        "  worldbody = root.find(\"worldbody\")\n",
        "  asset = root.find(\"asset\")\n",
        "\n",
        "  ET.SubElement(\n",
        "      asset,\n",
        "      \"hfield\",\n",
        "      name=\"hfield_geom\",\n",
        "      # pos=\"0 0 0\",\n",
        "      nrow=f\"{CONFIG.training.height_field_grid_size}\",\n",
        "      ncol=f\"{CONFIG.training.height_field_grid_size}\",\n",
        "      elevation = ' '.join(scaled_noise.astype(str).flatten().tolist()),\n",
        "      size=f\"{CONFIG.training.height_field_radius_x} {CONFIG.training.height_field_radius_y} {CONFIG.training.height_field_elevation_z} {CONFIG.training.height_field_base_z}\",\n",
        "  )\n",
        "\n",
        "  ET.SubElement(\n",
        "      worldbody,\n",
        "      \"geom\",\n",
        "      name=\"hfield_floor\",\n",
        "      type=\"hfield\",\n",
        "      hfield=\"hfield_geom\",\n",
        "      # rgba=\"0.1 0.5 0.8 1\",\n",
        "      material=\"grid\",\n",
        "      conaffinity=\"1\",\n",
        "      contype=\"1\",\n",
        "      condim=\"3\",\n",
        "      group=CONFIG.training.height_field_group,\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs8tulPnA_WX"
      },
      "source": [
        "## Write new model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVg1ha0SA-zT"
      },
      "outputs": [],
      "source": [
        "with open(CONFIG.simulation.model_path,'w+') as file:\n",
        "  tree.write(file, encoding='unicode')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t9wIBXHfELi"
      },
      "source": [
        "# Benchmark pupper model\n",
        "Typically can go ~2.8M steps/s on L4 GPU on planar ground with 5 max contact points and 4 max geom pairs\n",
        "\n",
        "* 300k step/s with pts=15, pairs=15 with 20 ledge obstacles\n",
        "* 2.4M step/s with pts=8, pairs=8 with 0 obstacles\n",
        "* 2.0M step/s with pts=8, pairs=8 with 1 obstacles\n",
        "* 1.5M step/s with hfield, 4 feet, no ground plane, no box body\n",
        "* 1.1M step/s with hfield, 4 feet + 4 elbows, no box body, self collision enabled\n",
        "* 1.0M step/s with hfield, 4 feet + 4 elbows, no ground plane, no box body\n",
        "* 640k step/s with pts=8, pairs=8 with 10 ledge obstacles\n",
        "* 600k step/s with pts=8, pairs=8 with 20 ledge obstacles\n",
        "* 560k step/s with pts=8, pairs=8 with 100 ledge obstacles\n",
        "* 120k step/s with hfield, box body, 8 spheres, plane ground\n",
        "* 65k step/s  with pts=8, pairs=8 with 300 ledges\n",
        "\n",
        "no_ground.xml: 120k/s\n",
        "\n",
        "A100 GPU\n",
        "* 4.58M step/s with pts=8, pairs=8, no knee motor collision boxes\n",
        "* 4.5M step/s with pts=8, pairs=8, 0 ledge obstacles\n",
        "* 2.4M step/s with hfield, 4 feet + 4 elbows, no box body\n",
        "* 1.7M step/s with pts=8, pairs=8, 10 ledge obstacles\n",
        "* 2.1M step/s with pts=8, pairs=8, hfield, elliptic\n",
        "* 2.2M step/s with pts=8, pairs=8, hfield, pyramidal\n",
        "* 2.4M step/s with pts=5, pairs=4, hfield, pyramidal\n",
        "* 1.1M step/s with pts=50, pairs=50, hfield, pyramidal\n",
        "* 2.1M step/s with pts=8, pairs=8, hfield, elliptic, ls_iterations=50, iterations=100\n",
        "* 2.1M step/s with pts=8, pairs=8, hfield, elliptic, ls_iterations=50, iterations=10\n",
        "* 1.85M step/s with frictionloss, hfield, pyramidal, 10, 10 pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6FWHSo_omSR"
      },
      "outputs": [],
      "source": [
        "from mujoco.mjx import benchmark\n",
        "\n",
        "jax.config.update('jax_default_matmul_precision', 'high')\n",
        "sys = mjcf.load(CONFIG.simulation.model_path)\n",
        "jit_time, run_time, steps = benchmark(sys.mj_model, batch_size=CONFIG.training.ppo.num_envs)\n",
        "physics_steps_per_sec = steps / run_time\n",
        "print('Steps per sec: ', physics_steps_per_sec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efnxNOnpQFuC"
      },
      "source": [
        "# Pupper V3 Env\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-PvI2gexJQ3"
      },
      "source": [
        "## Create Pupper V3 Env\n",
        "\n",
        "This is the mjx environment that we will use for training!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y79PoJOCIl-O"
      },
      "outputs": [],
      "source": [
        "from pupperv3_mjx import environment\n",
        "import importlib\n",
        "importlib.reload(environment)\n",
        "\n",
        "envs.register_environment('pupper', environment.PupperV3Env)\n",
        "\n",
        "env_kwargs = dict(path=CONFIG.simulation.model_path,\n",
        "                  action_scale=CONFIG.policy.action_scale,\n",
        "                  observation_history=CONFIG.policy.observation_history,\n",
        "                  joint_lower_limits=joint_lower_limits,\n",
        "                  joint_upper_limits=joint_upper_limits,\n",
        "                  dof_damping=CONFIG.training.dof_damping,\n",
        "                  position_control_kp=CONFIG.training.position_control_kp,\n",
        "                  foot_site_names=CONFIG.simulation.foot_site_names,\n",
        "                  torso_name=CONFIG.simulation.torso_name,\n",
        "                  upper_leg_body_names=CONFIG.simulation.upper_leg_body_names,\n",
        "                  lower_leg_body_names=CONFIG.simulation.lower_leg_body_names,\n",
        "                  resample_velocity_step=CONFIG.training.resample_velocity_step,\n",
        "                  linear_velocity_x_range=CONFIG.training.lin_vel_x_range,\n",
        "                  linear_velocity_y_range=CONFIG.training.lin_vel_y_range,\n",
        "                  angular_velocity_range=CONFIG.training.ang_vel_yaw_range,\n",
        "                  zero_command_probability=CONFIG.training.zero_command_probability,\n",
        "                  stand_still_command_threshold=CONFIG.training.stand_still_command_threshold,\n",
        "                  maximum_pitch_command=CONFIG.training.maximum_pitch_command,\n",
        "                  maximum_roll_command=CONFIG.training.maximum_roll_command,\n",
        "                  start_position_config=CONFIG.training.start_position_config,\n",
        "                  default_pose=CONFIG.training.default_pose,\n",
        "                  desired_abduction_angles=CONFIG.training.desired_abduction_angles,\n",
        "                  reward_config=CONFIG.reward,\n",
        "                  angular_velocity_noise=CONFIG.training.angular_velocity_noise,\n",
        "                  gravity_noise=CONFIG.training.gravity_noise,\n",
        "                  motor_angle_noise=CONFIG.training.motor_angle_noise,\n",
        "                  last_action_noise=CONFIG.training.last_action_noise,\n",
        "                  kick_vel = CONFIG.training.kick_vel,\n",
        "                  kick_probability = CONFIG.training.kick_probability,\n",
        "                  terminal_body_z=CONFIG.training.terminal_body_z,\n",
        "                  early_termination_step_threshold=CONFIG.training.early_termination_step_threshold,\n",
        "                  terminal_body_angle=CONFIG.training.terminal_body_angle,\n",
        "                  foot_radius=CONFIG.simulation.foot_radius,\n",
        "                  environment_timestep=CONFIG.training.environment_dt,\n",
        "                  physics_timestep=CONFIG.simulation.physics_dt,\n",
        "                  latency_distribution=CONFIG.training.latency_distribution,\n",
        "                  imu_latency_distribution=CONFIG.training.imu_latency_distribution,\n",
        "                  desired_world_z_in_body_frame=jp.array(CONFIG.training.desired_world_z_in_body_frame),\n",
        "                  use_imu=CONFIG.policy.use_imu,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pi_yrcz-Qp3W"
      },
      "outputs": [],
      "source": [
        "import mujoco\n",
        "\n",
        "# Debug: Print available body names to help fix the config\n",
        "try:\n",
        "    print(f\"Inspecting model at: {CONFIG.simulation.model_path}\")\n",
        "    m = mujoco.MjModel.from_xml_path(CONFIG.simulation.model_path)\n",
        "    body_names = [mujoco.mj_id2name(m, mujoco.mjtObj.mjOBJ_BODY, i) for i in range(m.nbody)]\n",
        "    print(f\"All Body Names in Model: {body_names}\")\n",
        "\n",
        "    # Identify missing bodies\n",
        "    missing_lower = [name for name in env_kwargs['lower_leg_body_names'] if name not in body_names]\n",
        "    if missing_lower:\n",
        "        print(f\"\\n[ERROR] The following lower_leg_body_names are missing: {missing_lower}\")\n",
        "        print(\"Please update 'simulation_config.lower_leg_body_names' in the Config section with names from the list above.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Could not inspect model: {e}\")\n",
        "\n",
        "print(\"-\"*30)\n",
        "\n",
        "env_name = 'pupper'\n",
        "env = envs.get_environment(env_name, **env_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVsJY3ML2Jb6"
      },
      "source": [
        "## Visualize single env\n",
        "\n",
        "Let's visualize Pupper in our training environment!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e35uuUorihI"
      },
      "outputs": [],
      "source": [
        "visualization_env = envs.get_environment(env_name, **env_kwargs)\n",
        "\n",
        "# initialize the state\n",
        "rng = jax.random.PRNGKey(1)\n",
        "\n",
        "jit_reset = jax.jit(visualization_env.reset)\n",
        "jit_step = jax.jit(visualization_env.step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2ckSVIktgj8"
      },
      "outputs": [],
      "source": [
        "state = jit_reset(rng)\n",
        "state.info['command'] = jp.array([0, 0, 0])\n",
        "\n",
        "rollout = [state.pipeline_state]\n",
        "states = [state]\n",
        "\n",
        "# grab a trajectory\n",
        "n_steps = 200\n",
        "render_every = 2\n",
        "\n",
        "for i in range(n_steps):\n",
        "  act_rng, rng = jax.random.split(rng)\n",
        "  ctrl = jp.array(np.random.uniform(low=-1.0, high=1.0, size=sys.nu))*0.5\n",
        "  state = jit_step(state, ctrl)\n",
        "  rollout.append(state.pipeline_state)\n",
        "  states.append(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLJhubCArl36"
      },
      "outputs": [],
      "source": [
        "media.show_video(\n",
        "    visualization_env.render(rollout[::render_every], camera='tracking_cam'),\n",
        "    fps=1.0 / visualization_env.dt / render_every)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGM_fwFNPhZk"
      },
      "outputs": [],
      "source": [
        "states[-1].info[\"rewards\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A brief visualization of the 12 motors during the evaluation rollout. They should follow an IID uniform distribution:"
      ],
      "metadata": {
        "id": "yIQlB61qlRQs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVRgHQ09WBZb"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "x_axis = list(range(len(states)))\n",
        "y_axis = [state.pipeline_state.qpos for state in states]\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "for i in range(y_axis[0].shape[0]):\n",
        "  fig.add_trace(go.Scatter(x=x_axis, y=[qpos[i] for qpos in y_axis],\n",
        "                         mode='lines',\n",
        "                         name=f'Joint {i}'))\n",
        "\n",
        "fig.update_layout(title='Joint Positions over Time',\n",
        "                  xaxis_title='Timestep',\n",
        "                  yaxis_title='Joint Position')\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxaNFP9mA23H"
      },
      "source": [
        "# Train Policy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6ty6pabkmW3"
      },
      "source": [
        "## Expected Reward (from Nathan)\n",
        "\n",
        "- **Episode length = 1000** → Expected reward: **30+**\n",
        "- **Episode length = 500** → Expected reward: **15+**\n",
        "\n",
        "Keep in mind that the expected reward values depend heavily on the **scale of your reward coefficients**!  \n",
        "In general, seeing your reward increase during training is a **positive sign**.  \n",
        "However, always **watch the training videos** to better understand how your policy is actually behaving.\n",
        "\n",
        "---\n",
        "\n",
        "### Friendly Reminder\n",
        "If you terminate the training cell below, make sure to run:\n",
        "\n",
        "```python\n",
        "wandb.finish()\n",
        "```\n",
        "\n",
        "**before** starting a new training run.  \n",
        "Otherwise, the training cell will fail to execute properly!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#wandb.finish()"
      ],
      "metadata": {
        "id": "okM9U92HoH2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHJCbESGA7Rk"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from pupperv3_mjx import utils\n",
        "import importlib\n",
        "importlib.reload(utils)\n",
        "\n",
        "train_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "\n",
        "# Prompt user for run name\n",
        "print(\"Please enter a name for this run in the box below.\")\n",
        "run_name = input(\"Run Name (press Enter for auto-generated): \").strip()\n",
        "if not run_name:\n",
        "    run_name = None\n",
        "\n",
        "try:\n",
        "    wandb.init(entity=None,\n",
        "               project=\"Wheels_and_legs\",\n",
        "               name=run_name,\n",
        "               config=CONFIG.to_dict(),\n",
        "               save_code=True,\n",
        "               settings={\n",
        "                \"_service_wait\": 90,\n",
        "                \"init_timeout\": 90\n",
        "               })\n",
        "    print(\"Using personal W&B to log training progress.\")\n",
        "except wandb.errors.CommError:\n",
        "    print(\"W&B failed to initialize. Training without logging (follow W&B specific cells may fail)\")\n",
        "\n",
        "try:\n",
        "    wandb.run.summary[\"benchmark_physics_steps_per_sec\"] = physics_steps_per_sec\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Save and reload params.\n",
        "output_folder = f\"output_{wandb.run.name}\"\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Create and JIT reset and step functions for use in in-training policy\n",
        "# video creation if they don't already exist from a previous step\n",
        "if (\"jit_reset\" in globals() or \"jit_reset\" in locals()) and (\n",
        "    \"jit_step\" in globals() or \"jit_step\" in locals()\n",
        "):\n",
        "    print(\"JIT'd step and reset functions already defined. \" \"Using them for policy visualization.\")\n",
        "else:\n",
        "    print(\"Creating and JIT'ing step and reset functions\")\n",
        "    policy_viz_env = envs.get_environment(env_name, **env_kwargs)\n",
        "    jit_reset = jax.jit(policy_viz_env.reset)\n",
        "    jit_step = jax.jit(policy_viz_env.step)\n",
        "\n",
        "\n",
        "make_networks_factory = functools.partial(\n",
        "    ppo_networks.make_ppo_networks,\n",
        "    policy_hidden_layer_sizes=CONFIG.policy.hidden_layer_sizes,\n",
        "    activation=utils.activation_fn_map(CONFIG.policy.activation)\n",
        ")\n",
        "train_fn = functools.partial(\n",
        "    ppo.train,\n",
        "    **(CONFIG.training.ppo.to_dict()),\n",
        "    network_factory=make_networks_factory,\n",
        "    randomization_fn=functools.partial(\n",
        "        domain_randomization.domain_randomize,\n",
        "        friction_range=CONFIG.training.friction_range,\n",
        "        kp_multiplier_range=CONFIG.training.position_control_kp_multiplier_range,\n",
        "        kd_multiplier_range=CONFIG.training.position_control_kd_multiplier_range,\n",
        "        body_com_x_shift_range=CONFIG.training.body_com_x_shift_range,\n",
        "        body_com_y_shift_range=CONFIG.training.body_com_y_shift_range,\n",
        "        body_com_z_shift_range=CONFIG.training.body_com_z_shift_range,\n",
        "        body_mass_scale_range=CONFIG.training.body_mass_scale_range,\n",
        "        body_inertia_scale_range=CONFIG.training.body_inertia_scale_range,\n",
        "    ),\n",
        "    seed=28,\n",
        ")\n",
        "\n",
        "x_data = []\n",
        "y_data = []\n",
        "ydataerr = []\n",
        "times = [datetime.now()]\n",
        "\n",
        "env = envs.get_environment(env_name, **env_kwargs)\n",
        "eval_env = envs.get_environment(env_name, **env_kwargs)\n",
        "\n",
        "def policy_params_fn(current_step, make_policy, params):\n",
        "    utils.visualize_policy(current_step=current_step,\n",
        "                           make_policy=make_policy,\n",
        "                           params=params,\n",
        "                           eval_env=eval_env,\n",
        "                           jit_step=jit_step,\n",
        "                           jit_reset=jit_reset,\n",
        "                           output_folder=output_folder)\n",
        "    utils.save_checkpoint(current_step=current_step,\n",
        "                          make_policy=make_policy,\n",
        "                          params=params,\n",
        "                          checkpoint_path=output_folder)\n",
        "\n",
        "from pathlib import Path\n",
        "checkpoint_kwargs = {}\n",
        "if CONFIG.training.checkpoint_run_number is not None:\n",
        "  utils.download_checkpoint(entity_name=ENTITY,\n",
        "                            project_name=\"pupperv3-mjx-rl\",\n",
        "                            run_number=CONFIG.training.checkpoint_run_number,\n",
        "                            save_path=\"checkpoint\")\n",
        "  checkpoint_kwargs[\"restore_checkpoint_path\"]=Path(\"checkpoint\").resolve()\n",
        "\n",
        "make_inference_fn, params, _ = train_fn(\n",
        "    environment=env,\n",
        "    progress_fn=functools.partial(\n",
        "        utils.progress,\n",
        "        times=times,\n",
        "        x_data=x_data,\n",
        "        y_data=y_data,\n",
        "        ydataerr=ydataerr,\n",
        "        num_timesteps= CONFIG.training.ppo.num_timesteps,\n",
        "        min_y=0,\n",
        "        max_y=40,\n",
        "    ),\n",
        "    eval_env=eval_env,\n",
        "    policy_params_fn=policy_params_fn,\n",
        "    **checkpoint_kwargs\n",
        ")\n",
        "\n",
        "print(f\"time to jit: {times[1] - times[0]}\")\n",
        "wandb.run.summary[\"time_to_jit\"] = (times[1] - times[0]).total_seconds()\n",
        "wandb.run.summary[\"time_to_train\"] = (times[-1] - times[1]).total_seconds()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gKNUa4MLDagl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Yge-CGP5JoO"
      },
      "outputs": [],
      "source": [
        "# Save params to a model\n",
        "model_path = os.path.join(output_folder, f'mjx_params_{train_datetime}')\n",
        "model.save_params(model_path, params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L01IrN4oCIkC"
      },
      "source": [
        "# Visualize Policy\n",
        "\n",
        "For the Barkour Quadruped, the joystick commands can be set through `x_vel`, `y_vel`, and `ang_vel`. `x_vel` and `y_vel` define the linear forward and sideways velocities with respect to the quadruped torso. `ang_vel` defines the angular velocity of the torso in the z direction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTbpEtXnEecd"
      },
      "outputs": [],
      "source": [
        "inference_fn = make_inference_fn(params)\n",
        "jit_inference_fn = jax.jit(inference_fn)\n",
        "eval_env = envs.get_environment(env_name, **env_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRRN-8L-BivZ"
      },
      "outputs": [],
      "source": [
        "# @markdown Commands **only used for Pupper Env**:\n",
        "x_vel = 0.75  #@param {type: \"number\"}\n",
        "y_vel = 0.  #@param {type: \"number\"}\n",
        "ang_vel = 0.  #@param {type: \"number\"}\n",
        "\n",
        "the_command = jp.array([x_vel, y_vel, ang_vel])\n",
        "\n",
        "# initialize the state\n",
        "rng = jax.random.PRNGKey(0)\n",
        "state = jit_reset(rng)\n",
        "state.info['command'] = the_command\n",
        "pitch_rad = 0.\n",
        "state.info['desired_world_z_in_body_frame'] = jp.array([jp.sin(pitch_rad),\n",
        "                                                        0.0,\n",
        "                                                        jp.cos(pitch_rad)])\n",
        "rollout = [state.pipeline_state]\n",
        "\n",
        "# grab a trajectory\n",
        "n_steps = 300\n",
        "render_every = 2\n",
        "ctrls = []\n",
        "\n",
        "for i in range(n_steps):\n",
        "  act_rng, rng = jax.random.split(rng)\n",
        "\n",
        "  ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
        "  state = jit_step(state, ctrl)\n",
        "  rollout.append(state.pipeline_state)\n",
        "  ctrls.append(ctrl)\n",
        "\n",
        "media.show_video(\n",
        "    eval_env.render(rollout[::render_every], camera='tracking_cam'),\n",
        "    fps=1.0 / eval_env.dt / render_every)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBeQeuPkWlhi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from pupperv3_mjx import plotting\n",
        "plotting.plot_multi_series(data=np.array(ctrls), dt=0.02, display_axes=[0,1,2], title=\"Policy output\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MTsReLS43xD"
      },
      "outputs": [],
      "source": [
        "torques = jp.array([rollout[i].qfrc_actuator[6:] for i in range(len(rollout))]) # ignore world-body joint\n",
        "plotting.plot_multi_series(data=torques, dt=0.02, display_axes=[0, 1, 2], title=\"Joint torques\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eImaSgpZCP3j"
      },
      "outputs": [],
      "source": [
        "joint_pos = jp.array([rollout[i].q[7:] for i in range(len(rollout))]) # ignore world-body joint\n",
        "plotting.plot_multi_series(data=joint_pos, dt=0.02, display_axes=[0, 1, 2], title=\"Joint Positions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mN8Y1QChNRH"
      },
      "outputs": [],
      "source": [
        "world_vel = jp.array([rollout[i].qvel[:3] for i in range(len(rollout))])\n",
        "plotting.plot_multi_series(data=world_vel, dt=0.02, display_axes=[0, 1, 2], title=\"World Velocity\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDo1W2nkjeG6"
      },
      "source": [
        "# Export Policy for neural_controller"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-gvFL6zi5CY"
      },
      "source": [
        "After running the following cells, open the files tab on the left and download policy.json."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWFgxqB71E4O"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pupperv3_mjx import export\n",
        "params_rtneural = export.convert_params(jax.block_until_ready(params),\n",
        "                                        activation=CONFIG.policy.activation,\n",
        "                                        action_scale=CONFIG.policy.action_scale,\n",
        "                                        kp=CONFIG.training.position_control_kp,\n",
        "                                        kd=CONFIG.training.dof_damping,\n",
        "                                        default_pose=CONFIG.training.default_pose,\n",
        "                                        joint_upper_limits=CONFIG.simulation.joint_upper_limits,\n",
        "                                        joint_lower_limits=CONFIG.simulation.joint_lower_limits,\n",
        "                                        use_imu=CONFIG.policy.use_imu,\n",
        "                                        observation_history=CONFIG.policy.observation_history,\n",
        "                                        final_activation=\"tanh\",\n",
        "                                        maximum_pitch_command=CONFIG.training.maximum_pitch_command,\n",
        "                                        maximum_roll_command=CONFIG.training.maximum_roll_command\n",
        "                                        )\n",
        "\n",
        "name = f\"policy.json\"\n",
        "saved_policy_filename = os.path.join(output_folder, name)\n",
        "with open(saved_policy_filename, \"w\") as f:\n",
        "  json.dump(params_rtneural, f)\n",
        "\n",
        "wandb.log_model(path=saved_policy_filename, name=name)\n",
        "wandb.log_model(path=model_path, name=f\"mjx_policy_network_{wandb.run.name}.pt\")\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SAVE POLICY TO GOOGLE DRIVE\n",
        "# ============================================================================\n",
        "# Copy this entire cell into your Colab notebook as the LAST cell.\n",
        "# It will:\n",
        "#   1. Mount Google Drive\n",
        "#   2. Copy the trained policy folder to Google Drive\n",
        "#   3. Unassign the runtime to save credits\n",
        "#\n",
        "# Prerequisites:\n",
        "#   - 'output_folder' must be defined from the training cell (line ~2027):\n",
        "#       output_folder = f\"output_{wandb.run.name}\"\n",
        "# ============================================================================\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "from google.colab import runtime\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Define Output Paths\n",
        "# 'output_folder' should be defined in the previous cells of the notebook\n",
        "source_path = output_folder\n",
        "\n",
        "# Define where in Drive to save. Change 'Pupper_Policies' if you prefer a different folder.\n",
        "drive_base_dir = '/content/drive/My Drive/Pupper_Policies'\n",
        "destination_path = os.path.join(drive_base_dir, os.path.basename(source_path))\n",
        "\n",
        "print(f\"Source: {source_path}\")\n",
        "print(f\"Destination: {destination_path}\")\n",
        "\n",
        "# 3. Copy files\n",
        "if os.path.exists(destination_path):\n",
        "    print(f\"Destination folder {destination_path} already exists. Removing it to overwrite...\")\n",
        "    shutil.rmtree(destination_path)\n",
        "\n",
        "print(\"Copying policy files to Google Drive...\")\n",
        "shutil.copytree(source_path, destination_path)\n",
        "print(\"Successfully saved policy to Google Drive!\")"
      ],
      "metadata": {
        "id": "DeVj_OCcD5pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMnVQjByig7K"
      },
      "source": [
        "After you are done training and have downloaded the policy, remember to shut down the runtime to save money!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "YvyGCsgSCxHQ",
        "d7y2mHlcs-uc",
        "y-gxymQh6gQg",
        "ncR52Hvl3ZOn",
        "mi69q6o5X8qC",
        "YrkA-Nhi1ora",
        "I-PvI2gexJQ3"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}